{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import mir_eval\n",
    "from time import time\n",
    "from fnmatch import fnmatch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from thundersvm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer  # for imputation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of audio files: 4\n",
      "85SM_2020-01-27_14-40-03.wav\n",
      "87SM_2020-01-27_15-43-59.wav\n",
      "89SF_2020-01-27_16-51-22.wav\n",
      "91SM_2020-01-30_10-20-53.wav\n",
      "Chick ID: 85 87 89 91\n"
     ]
    }
   ],
   "source": [
    "data_root = 'data/'\n",
    "wav_files = [] \n",
    "with open('file_names.txt', 'r') as f:\n",
    "    Lines = f.readlines()\n",
    "    for line in Lines: \n",
    "        wav_files.append(line.strip())\n",
    "        \n",
    "print('Number of audio files:', format(len(wav_files)))\n",
    "print(*wav_files, sep='\\n')\n",
    "\n",
    "# chick call annotation files\n",
    "csv_files = [file.replace('.wav', '.csv') for file in wav_files]\n",
    "chickID = [int(wav_files[k][:2]) for k in range(len(wav_files))]\n",
    "print('Chick ID:', *chickID, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chickID</th>\n",
       "      <th>callID</th>\n",
       "      <th>truth_start</th>\n",
       "      <th>truth_end</th>\n",
       "      <th>truth_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336961</td>\n",
       "      <td>0.595465</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>0.830385</td>\n",
       "      <td>1.137415</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>1.258957</td>\n",
       "      <td>1.551020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>1.659864</td>\n",
       "      <td>1.991837</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>91</td>\n",
       "      <td>3008</td>\n",
       "      <td>629.097506</td>\n",
       "      <td>629.471202</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>91</td>\n",
       "      <td>3009</td>\n",
       "      <td>632.406349</td>\n",
       "      <td>632.756825</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>91</td>\n",
       "      <td>3010</td>\n",
       "      <td>632.883809</td>\n",
       "      <td>633.269841</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>91</td>\n",
       "      <td>3011</td>\n",
       "      <td>633.361270</td>\n",
       "      <td>633.747302</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>91</td>\n",
       "      <td>3012</td>\n",
       "      <td>633.848889</td>\n",
       "      <td>634.255238</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3013 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chickID  callID  truth_start   truth_end truth_label\n",
       "0          85       0     0.000000    0.123356           1\n",
       "1          85       1     0.336961    0.595465           2\n",
       "2          85       2     0.830385    1.137415           2\n",
       "3          85       3     1.258957    1.551020           2\n",
       "4          85       4     1.659864    1.991837           2\n",
       "...       ...     ...          ...         ...         ...\n",
       "3008       91    3008   629.097506  629.471202           2\n",
       "3009       91    3009   632.406349  632.756825           2\n",
       "3010       91    3010   632.883809  633.269841           2\n",
       "3011       91    3011   633.361270  633.747302           2\n",
       "3012       91    3012   633.848889  634.255238           2\n",
       "\n",
       "[3013 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get call segment information\n",
    "anno = []\n",
    "for file in csv_files:\n",
    "    file_anno = pd.read_csv(data_root+file)\n",
    "    file_anno['chick'] = [int(file[:2])] * len(file_anno)\n",
    "    anno.append(file_anno)\n",
    "    \n",
    "anno = pd.concat(anno, axis=0, ignore_index=True)\n",
    "\n",
    "call_segs = pd.DataFrame({'chickID':[], 'callID':[], 'truth_start': [], 'truth_end': [], 'truth_label':[]})\n",
    "call_segs['chickID'] = list(anno['chick'][1::2])\n",
    "call_segs['callID'] = np.arange(len(call_segs['chickID']), dtype=int)\n",
    "call_segs['truth_start'] = list(anno['time'][0::2])\n",
    "call_segs['truth_end'] = list(anno['time'][1::2])\n",
    "call_segs['truth_label'] = list(anno['anno'][1::2])\n",
    "\n",
    "call_segs.loc[(call_segs.truth_label == 'p'),'truth_label']= 1\n",
    "call_segs.loc[(call_segs.truth_label == 'd'),'truth_label']= 2\n",
    "call_segs.loc[(call_segs.truth_label == 'q'),'truth_label']= 3\n",
    "call_segs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JTFS feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load extracted JTFS feature\n",
    "joint = scipy.io.loadmat('JTFS_feature.mat')['fileFeatures'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame size: 92ms\n",
      "frame samples: 4096\n"
     ]
    }
   ],
   "source": [
    "# scattering params used\n",
    "sr = 44100\n",
    "T = 2**14\n",
    "oversampling = 2\n",
    "hop_sample = int(T/(2**oversampling))\n",
    "print('frame size: %sms' % (int(hop_sample/44100*1000)))\n",
    "print('frame samples: %d' % hop_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(850, 7322)\n",
      "(850, 7299)\n",
      "(850, 6915)\n",
      "(850, 6844)\n"
     ]
    }
   ],
   "source": [
    "feature = {k: np.vstack((joint[k], joint[k])) for k in range(len(joint))}\n",
    "\n",
    "for k in range(len(joint)):\n",
    "    for m in range(2,joint[k].shape[1]-2):\n",
    "        feature[k][:joint[k].shape[0],m] = np.mean(joint[k][:,m-2:m+3], axis=1)\n",
    "        feature[k][joint[k].shape[0]:, m] = np.std(joint[k][:,m-2:m+3], axis=1)\n",
    "del(joint)\n",
    "\n",
    "for k in range(len(feature)):\n",
    "    print(feature[k].shape)\n",
    "    \n",
    "feature_conca = np.zeros((feature[0].shape[0],1))\n",
    "chick_id = []\n",
    "\n",
    "for k in range(len(wav_files)):\n",
    "    feature_conca = np.hstack((feature_conca, feature[k]))\n",
    "    chick_id.extend([int(wav_files[k][:2])] * feature[k].shape[1])\n",
    "        \n",
    "chick_id = np.array(chick_id)\n",
    "feature_conca = np.transpose(feature_conca)\n",
    "feature_conca = feature_conca[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame-wise label_id and call_id\n",
    "frame_num = []\n",
    "label_id = np.zeros((len(chick_id)), dtype=int)   # 1=pleasure, 2=distress, 3=uncertain\n",
    "call_id = np.zeros((len(chick_id)), dtype=int)\n",
    "\n",
    "for chick in range(len(wav_files)):\n",
    "    frame_num.append(feature[chick].shape[1])\n",
    "    seg_chick = call_segs[call_segs['chickID']==int(wav_files[chick][:2])]\n",
    "    sample_start = list(map(lambda x:int(x * sr / hop_sample) + sum(frame_num[:chick]), seg_chick['truth_start']))\n",
    "    sample_end = list(map(lambda x:int(x * sr / hop_sample) + sum(frame_num[:chick]), seg_chick['truth_end']))\n",
    "    \n",
    "    for k in range(len(seg_chick)): # for each sample\n",
    "        label_id[sample_start[k]:sample_end[k]] = np.zeros((sample_end[k]-sample_start[k])) + list(seg_chick['truth_label'])[k]\n",
    "        call_id[sample_start[k]:sample_end[k]] = np.zeros((sample_end[k]-sample_start[k])) + list(seg_chick['callID'])[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28380, 850) (28380,) (28380,) (28380,)\n"
     ]
    }
   ],
   "source": [
    "print(feature_conca.shape, chick_id.shape, call_id.shape, label_id.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM settings\n",
    "kernel = 'rbf'\n",
    "gpu_id = 0 # thundersvm uses GPU to train SVM classifier\n",
    "param_grid = {'C': [100,10,1], 'gamma': [.0001, .001, .01]}\n",
    "scoring = 'f1_macro'\n",
    "cv = 3\n",
    "\n",
    "F_event = []; F_frame = []\n",
    "dur = .5  # for event-based evaluation: duration of detected event should be at least 50% of the ground truth duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subject-independent train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21058, 850) (7322, 850)\n",
      "(442, 4) (820, 4)\n",
      "0.04825389999996332 0.09287981859410431 0.09287981859410431\n",
      "(21081, 850) (7299, 850)\n",
      "(1078, 4) (2266, 4)\n",
      "0.03936509999994087 0.09287981859410431 0.09287981859410431\n",
      "(21465, 850) (6915, 850)\n",
      "(179, 4) (1425, 4)\n",
      "0.03936509999994087 0.09287981859410431 0.09287981859410431\n",
      "(21536, 850) (6844, 850)\n",
      "(99, 4) (959, 4)\n",
      "0.03936509999994087 0.09287981859410431 0.09287981859410431\n"
     ]
    }
   ],
   "source": [
    "for chick in chickID:\n",
    "    subset = np.ones((len(label_id)), dtype=int) * 100\n",
    "\n",
    "    for k in range(len(label_id)):\n",
    "        if chick_id[k] != chick:\n",
    "            subset[k] = 0\n",
    "        else:\n",
    "            subset[k] = 1\n",
    "\n",
    "    feature_tr, label_tr = feature_conca[subset == 0], label_id[subset == 0]\n",
    "    feature_te, label_te = feature_conca[subset == 1], label_id[subset == 1]\n",
    "\n",
    "    # imputation\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    feature_tr = imp.fit_transform(feature_tr)\n",
    "    feature_te = imp.transform(feature_te)\n",
    "\n",
    "    # standardisation\n",
    "    stdscaler = StandardScaler()\n",
    "    feature_tr = stdscaler.fit_transform(feature_tr)\n",
    "    feature_te = stdscaler.transform(feature_te)\n",
    "    print(feature_tr.shape, feature_te.shape)\n",
    "\n",
    "    # classification\n",
    "    clf =  GridSearchCV(SVC(kernel=kernel, gpu_id=gpu_id), param_grid=param_grid, cv=cv, scoring=scoring)\n",
    "    clf = clf.fit(feature_tr, label_tr)\n",
    "    label_pred = clf.predict(feature_te)\n",
    "    \n",
    "    ###### frame-based evaluation ######\n",
    "    report = pd.DataFrame(classification_report(label_te, label_pred, output_dict=True))\n",
    "    F_frame.append([chick, report['1']['f1-score'], report['2']['f1-score'], report['3']['f1-score']])\n",
    "    \n",
    "    ###### event-based evaluation ######\n",
    "    trainDur = []\n",
    "    for k in range(len(call_segs)): \n",
    "        if call_segs['chickID'][k] != chick:   # [chickID, callID, truth_start, truth_end, label]\n",
    "            trainDur.append(call_segs['truth_end'][k] - call_segs['truth_start'][k])\n",
    "    minDurTrain = min(trainDur)\n",
    "\n",
    "    frame_time = T / sr / (2**oversampling)\n",
    "\n",
    "    # pred events\n",
    "    pred = pd.DataFrame({'pred': label_pred}, dtype=int)\n",
    "    pred['block'] = (pred.pred.shift(1) != pred.pred).astype(int).cumsum()\n",
    "    pred_event = pred.reset_index().groupby(['block','pred'])['index'].apply(np.array)\n",
    "\n",
    "    # truth events\n",
    "    truth = pd.DataFrame({'truth': label_te}, dtype=int)\n",
    "    truth['block'] = (truth.truth.shift(1) != truth.truth).astype(int).cumsum()\n",
    "    truth_event = truth.reset_index().groupby(['block','truth'])['index'].apply(np.array)\n",
    "\n",
    "    # pred_event: [index, start, duration, label]\n",
    "    predAll = np.zeros((1,4), dtype=int); ind = 0\n",
    "    for key, elem in pred_event.items():\n",
    "        predAll =  np.vstack((predAll, np.array([ind, elem[0] * frame_time, (elem[-1]-elem[0]+1)* frame_time, key[1]])))\n",
    "        ind += 1\n",
    "    predAll=predAll[1:]; predAll_ori = predAll\n",
    "\n",
    "    # truth_event\n",
    "    truthAll = np.zeros((1,4), dtype=int); ind = 0\n",
    "    for key, elem in truth_event.items():\n",
    "        truthAll =  np.vstack((truthAll, np.array([ind, elem[0] * frame_time, (elem[-1]-elem[0]+1)* frame_time, key[1]])))\n",
    "        ind += 1\n",
    "    truthAll=truthAll[1:];  truthAll_ori = truthAll\n",
    "\n",
    "    print(predAll.shape, truthAll.shape)\n",
    "\n",
    "    # gap filling\n",
    "    count = 0; k = 0\n",
    "\n",
    "    while count < predAll.shape[0]-1:\n",
    "        if predAll[k+1,1] - (predAll[k,1]+predAll[k,2]) < minDurTrain: # start of next - end of current\n",
    "            predAll[k+1,2] = predAll[k+1,1] + predAll[k+1,2] - predAll[k,1]   # duration \n",
    "            predAll[k+1,1] = predAll[k,1]    # start move left\n",
    "            predAll = np.delete(predAll, k, 0)\n",
    "        else: \n",
    "            k += 1\n",
    "        count += 1\n",
    "\n",
    "    # minimum duration prunning\n",
    "    predAll=predAll[predAll[:,2]>=minDurTrain]\n",
    "    minDurPred = min(predAll[:,2])\n",
    "    print(minDurTrain, minDurPred, frame_time)\n",
    "\n",
    "    event_result = []\n",
    "    for label in range(1,len(np.unique(label_id))):\n",
    "        # should compare only the target events\n",
    "        predAll = predAll_ori; truthAll = truthAll_ori\n",
    "        predAll=predAll[predAll[:,3]==label]; truthAll=truthAll[truthAll[:,3]==label]\n",
    "\n",
    "        matched = mir_eval.util.match_events(truthAll[:,1], predAll[:,1],window=.2, distance=None)\n",
    "\n",
    "        # check each one on the duration\n",
    "        TP = 0\n",
    "        for k in range(len(matched)):\n",
    "            interval_truth = pd.Interval(truthAll[matched[k][0],1], truthAll[matched[k][0],2]+truthAll[matched[k][0],1])\n",
    "            interval_pred = pd.Interval(predAll[matched[k][1],1], predAll[matched[k][1],2]+predAll[matched[k][1],1])\n",
    "            if interval_truth.overlaps(interval_pred):\n",
    "                time_sorted = np.sort([truthAll[matched[k][0],1], truthAll[matched[k][0],2]+truthAll[matched[k][0],1], \n",
    "                      predAll[matched[k][1],1], predAll[matched[k][1],2]+predAll[matched[k][1],1]]) # start, end, start, end\n",
    "                event_dur = time_sorted[2] - time_sorted[1]\n",
    "                if event_dur / truthAll[matched[k][0],2] > dur: # at least half duration\n",
    "                     TP += 1\n",
    "\n",
    "        FN = len(truthAll[truthAll[:,3]==label]) - TP\n",
    "        FP = len(predAll[predAll[:,3]==label]) - TP\n",
    "\n",
    "        if TP != 0:\n",
    "            P_event = TP / (TP + FP) * 100; R_event = TP / (TP + FN) * 100; \n",
    "            event_result.extend([2 * P_event * R_event / (P_event + R_event)])\n",
    "        else:\n",
    "            event_result.extend([0])\n",
    "            \n",
    "    F_event.append([chick] + event_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame-based F-scores for pleasure, contact, and uncertain calls: [10.5, 79.54, 6.25]\n",
      "Event-based F-scores for pleasure, contact, and uncertain calls: [7.04, 29.77, 1.41]\n"
     ]
    }
   ],
   "source": [
    "print('Frame-based F-scores for pleasure, contact, and uncertain calls: {}'.format(\n",
    "    [round(elem, 2) for elem in np.mean(F_frame,0)[1:]*100]))\n",
    "print('Event-based F-scores for pleasure, contact, and uncertain calls: {}'.format(\n",
    "    [round(elem, 2) for elem in np.mean(F_event,0)[1:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame-based average F-score: 32.1\n",
      "Event-based average F-score: 12.74\n"
     ]
    }
   ],
   "source": [
    "print('Frame-based average F-score: {}'.format(round(np.mean(np.mean(F_frame,0)[1:]*100), 2)))\n",
    "print('Event-based average F-score: {}'.format(round(np.mean(np.mean(F_event,0)[1:]), 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "188.014px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
