{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os, collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy, soundfile, librosa\n",
    "import mir_eval\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from fnmatch import fnmatch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from thundersvm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer  # for imputation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of audio files: 4\n",
      "85SM_2020-01-27_14-40-03.wav\n",
      "87SM_2020-01-27_15-43-59.wav\n",
      "89SF_2020-01-27_16-51-22.wav\n",
      "91SM_2020-01-30_10-20-53.wav\n",
      "Chick ID: 85 87 89 91\n"
     ]
    }
   ],
   "source": [
    "data_root = 'data/'\n",
    "wav_files = [] \n",
    "with open('file_names.txt', 'r') as f:\n",
    "    Lines = f.readlines()\n",
    "    for line in Lines: \n",
    "        wav_files.append(line.strip())\n",
    "        \n",
    "print('Number of audio files:', format(len(wav_files)))\n",
    "print(*wav_files, sep='\\n')\n",
    "\n",
    "# chick call annotation files\n",
    "csv_files = [file.replace('.wav', '.csv') for file in wav_files]\n",
    "chickID = [int(wav_files[k][:2]) for k in range(len(wav_files))]\n",
    "print('Chick ID:', *chickID, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chickID</th>\n",
       "      <th>callID</th>\n",
       "      <th>truth_start</th>\n",
       "      <th>truth_end</th>\n",
       "      <th>truth_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336961</td>\n",
       "      <td>0.595465</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>0.830385</td>\n",
       "      <td>1.137415</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>1.258957</td>\n",
       "      <td>1.551020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>1.659864</td>\n",
       "      <td>1.991837</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>91</td>\n",
       "      <td>3008</td>\n",
       "      <td>629.097506</td>\n",
       "      <td>629.471202</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>91</td>\n",
       "      <td>3009</td>\n",
       "      <td>632.406349</td>\n",
       "      <td>632.756825</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>91</td>\n",
       "      <td>3010</td>\n",
       "      <td>632.883809</td>\n",
       "      <td>633.269841</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>91</td>\n",
       "      <td>3011</td>\n",
       "      <td>633.361270</td>\n",
       "      <td>633.747302</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>91</td>\n",
       "      <td>3012</td>\n",
       "      <td>633.848889</td>\n",
       "      <td>634.255238</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3013 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chickID  callID  truth_start   truth_end truth_label\n",
       "0          85       0     0.000000    0.123356           1\n",
       "1          85       1     0.336961    0.595465           2\n",
       "2          85       2     0.830385    1.137415           2\n",
       "3          85       3     1.258957    1.551020           2\n",
       "4          85       4     1.659864    1.991837           2\n",
       "...       ...     ...          ...         ...         ...\n",
       "3008       91    3008   629.097506  629.471202           2\n",
       "3009       91    3009   632.406349  632.756825           2\n",
       "3010       91    3010   632.883809  633.269841           2\n",
       "3011       91    3011   633.361270  633.747302           2\n",
       "3012       91    3012   633.848889  634.255238           2\n",
       "\n",
       "[3013 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get call segs information\n",
    "anno = []\n",
    "for file in csv_files:\n",
    "    file_anno = pd.read_csv(data_root+file)\n",
    "    file_anno['chick'] = [int(file[:2])] * len(file_anno)\n",
    "    anno.append(file_anno)\n",
    "    \n",
    "anno = pd.concat(anno, axis=0, ignore_index=True)\n",
    "\n",
    "call_segs = pd.DataFrame({'chickID':[], 'callID':[], 'truth_start': [], 'truth_end': [], 'truth_label':[]})\n",
    "call_segs['chickID'] = list(anno['chick'][1::2])\n",
    "call_segs['callID'] = np.arange(len(call_segs['chickID']), dtype=int)\n",
    "call_segs['truth_start'] = list(anno['time'][0::2])\n",
    "call_segs['truth_end'] = list(anno['time'][1::2])\n",
    "call_segs['truth_label'] = list(anno['anno'][1::2])\n",
    "\n",
    "call_segs.loc[(call_segs.truth_label == 'p'),'truth_label']= 1\n",
    "call_segs.loc[(call_segs.truth_label == 'd'),'truth_label']= 2\n",
    "call_segs.loc[(call_segs.truth_label == 'q'),'truth_label']= 3\n",
    "call_segs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame size: 25ms\n",
      "MFCC feature shape: \n",
      "(24, 27189)\n",
      "(24, 27102)\n",
      "(24, 25678)\n",
      "(24, 25414)\n"
     ]
    }
   ],
   "source": [
    "sr = 44100\n",
    "hop_sample= 1103  # 25ms\n",
    "print('frame size: %sms' % (int(hop_sample/44100*1000)))\n",
    "\n",
    "# MFCC feature extraction, default: n_fft=2048, hop_length=512 \n",
    "feature = {k:[] for k in range(len(wav_files))}\n",
    "\n",
    "print('MFCC feature shape: ')\n",
    "for k in range(len(wav_files)):\n",
    "    y, sr = soundfile.read(data_root + wav_files[k])\n",
    "    y = np.mean(y,1)\n",
    "    feature[k] = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=24, hop_length=hop_sample)\n",
    "    print(feature[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_conca = np.zeros((feature[0].shape[0],1))\n",
    "chick_id = []\n",
    "\n",
    "for k in range(len(wav_files)):\n",
    "    feature_conca = np.hstack((feature_conca, feature[k]))\n",
    "    chick_id.extend([int(wav_files[k][:2])] * feature[k].shape[1])\n",
    "        \n",
    "chick_id = np.array(chick_id)\n",
    "feature_conca = np.transpose(feature_conca)\n",
    "feature_conca = feature_conca[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame-wise label_id and call_id\n",
    "frame_num = []\n",
    "label_id = np.zeros((len(chick_id)), dtype=int)   # 1=pleasure, 2=distress, 3=unknown\n",
    "call_id = np.zeros((len(chick_id)), dtype=int)\n",
    "\n",
    "for chick in range(len(wav_files)):\n",
    "    frame_num.append(feature[chick].shape[1])\n",
    "    seg_chick = call_segs[call_segs['chickID']== int(wav_files[chick][:2])]\n",
    "    sample_start = list(map(lambda x:int(x * sr / hop_sample) + sum(frame_num[:chick]), seg_chick['truth_start']))\n",
    "    sample_end = list(map(lambda x:int(x * sr / hop_sample) + sum(frame_num[:chick]), seg_chick['truth_end']))\n",
    "    \n",
    "    for k in range(len(seg_chick)): # for each sample\n",
    "        label_id[sample_start[k]:sample_end[k]] = np.zeros((sample_end[k]-sample_start[k])) + list(seg_chick['truth_label'])[k]\n",
    "        call_id[sample_start[k]:sample_end[k]] = np.zeros((sample_end[k]-sample_start[k])) + list(seg_chick['callID'])[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105383, 24) (105383,) (105383,) (105383,)\n"
     ]
    }
   ],
   "source": [
    "print(feature_conca.shape, chick_id.shape, label_id.shape, call_id.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detected segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_id = np.zeros((len(label_id)), dtype=int)\n",
    "call_id_pred = np.zeros((len(label_id)), dtype=int)\n",
    "\n",
    "segs = {k:[] for k in range(len(wav_files))}\n",
    "segs[0] = np.load('refined_segs.npz')['arr_0']\n",
    "segs[1] = np.load('refined_segs.npz')['arr_1']\n",
    "segs[2] = np.load('refined_segs.npz')['arr_2']\n",
    "segs[3] = np.load('refined_segs.npz')['arr_3']\n",
    "\n",
    "# format detected segments as [chick_id, call_id, start, end, label]\n",
    "seg_pred = []\n",
    "call_num_detect = [len(segs[k]) for k in range(len(segs))]\n",
    "\n",
    "for chick in range(len(wav_files)):\n",
    "    for k in range(len(segs[chick])):\n",
    "        seg_pred.append([int(wav_files[chick][:2]), k+sum(call_num_detect[:chick]), segs[chick][k,0], segs[chick][k,1], np.nan])\n",
    "        start_sam = int(np.floor(segs[chick][k,0] * sr / hop_sample)) + sum(frame_num[:chick])\n",
    "        end_sam = int(np.ceil(segs[chick][k,1] * sr / hop_sample)) + sum(frame_num[:chick])\n",
    "        label_pred_id[start_sam:end_sam] = np.zeros((end_sam-start_sam), dtype=int) + 100\n",
    "        call_id_pred[start_sam:end_sam] = np.zeros((end_sam-start_sam), dtype=int) + k+sum(call_num_detect[:chick])\n",
    "        \n",
    "seg_pred = np.array(seg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM settings\n",
    "kernel = 'rbf'\n",
    "gpu_id = 0 # thundersvm uses GPU to train SVM classifier\n",
    "param_grid = {'C': [100,10,1], 'gamma': [.0001, .001, .01]}\n",
    "scoring = 'f1_macro'\n",
    "cv = 3\n",
    "\n",
    "F_event = []; F_frame = []\n",
    "dur = .5  # for event-based evaluation: duration of detected event should be at least 50% of the ground truth duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for resampling predictions into the same frame size as that of the joint scattering feature \n",
    "# => for fair comparison of the reults\n",
    "inframeSize = hop_sample / 44100 # ms\n",
    "outframeSize = 0.186 # ms\n",
    "\n",
    "subsample_rate = int(outframeSize / inframeSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subject-independent train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c927c0003eb4c46b42540e22378bb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24802, 24) (6988, 24)\n",
      "(20405, 24) (9584, 24)\n",
      "(19087, 24) (10684, 24)\n",
      "(23792, 24) (7053, 24)\n"
     ]
    }
   ],
   "source": [
    "for chick in tqdm(chickID):\n",
    "    \n",
    "    subset = np.ones((len(label_id)), dtype=int) * 100\n",
    "\n",
    "    for k in range(len(label_id)):\n",
    "        if chick_id[k] != chick and label_id[k] != 0:  \n",
    "            subset[k] = 0\n",
    "        elif chick_id[k] == chick and label_pred_id[k] != 0:  # assign label for detected call segments\n",
    "            subset[k] = 1\n",
    "\n",
    "    feature_tr, label_tr = feature_conca[subset == 0], label_id[subset == 0]\n",
    "    feature_te, label_te = feature_conca[subset == 1], label_id[subset == 1]\n",
    "\n",
    "    # imputation\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    feature_tr = imp.fit_transform(feature_tr)\n",
    "    feature_te = imp.transform(feature_te)\n",
    "\n",
    "    # standardisation\n",
    "    stdscaler = StandardScaler()\n",
    "    feature_tr = stdscaler.fit_transform(feature_tr)\n",
    "    feature_te = stdscaler.transform(feature_te)\n",
    "    print(feature_tr.shape, feature_te.shape)\n",
    "\n",
    "    # classification\n",
    "    clf =  GridSearchCV(SVC(kernel=kernel, gpu_id=gpu_id), param_grid=param_grid, cv=cv, scoring=scoring)\n",
    "    clf = clf.fit(feature_tr, label_tr)\n",
    "    label_pred = clf.predict(feature_te)\n",
    "    \n",
    "    ########## frame-based evaluation ##########\n",
    "    # detected segments back into frame level\n",
    "    label_te_ori = label_id[chick_id==chick] # include label=0\n",
    "    label_pred_ori = label_pred_id[chick_id==chick] # include label=0\n",
    "    label_pred_true = np.zeros((len(label_te_ori)), dtype=int)\n",
    "    label_pred_true[label_pred_ori!=0] = label_pred\n",
    "    label_pred_true[label_pred_true==100] = 0\n",
    "    \n",
    "    # resample into the same frame size as that of the JTFS feature\n",
    "    label_te_ori = label_te_ori[::subsample_rate]\n",
    "    label_pred_true = label_pred_true[::subsample_rate]\n",
    "\n",
    "    report = pd.DataFrame(classification_report(label_te_ori, label_pred_true, output_dict=True))\n",
    "    F_frame.append([chick, report['1']['f1-score'], report['2']['f1-score'], report['3']['f1-score']])\n",
    "\n",
    "    ########## event-based evaluation ##########\n",
    "    # predicted segments: [chick_id, call_id, start, end, label]\n",
    "    call_id_test = call_id_pred[subset == 1]\n",
    "    _, idx = np.unique(call_id_test, return_index=True)\n",
    "    call_id_test_unique = call_id_test[np.sort(idx)]\n",
    "\n",
    "    seg_label_pred = []\n",
    "    for call in call_id_test_unique:\n",
    "        seg_label_pred.append(collections.Counter(label_pred[call_id_test==call]).most_common(1)[0][0])\n",
    "\n",
    "    pred_event = []\n",
    "\n",
    "    for k in call_id_test_unique:\n",
    "        pred_event.append(seg_pred[seg_pred[:,1] == k])\n",
    "    pred_event = np.squeeze(np.array(pred_event))\n",
    "    pred_event[:, -1] = seg_label_pred\n",
    "\n",
    "    truth_event = call_segs[call_segs['chickID'] == chick].to_numpy()\n",
    "\n",
    "    pred_event_ori = pred_event; truth_event_ori = truth_event\n",
    "\n",
    "    event_result = []\n",
    "    for label in range(1,len(np.unique(label_id))): # 1=pleasure, 2=distress, 3=uncertain\n",
    "        # should compare only the target events\n",
    "        pred_event = pred_event_ori; truth_event = truth_event_ori\n",
    "        pred_event=pred_event[pred_event[:,-1]==label]; truth_event=truth_event[truth_event[:,-1]==label] # label\n",
    "\n",
    "        matched = mir_eval.util.match_events(truth_event[:,2], pred_event[:,2],window=.2, distance=None) # start\n",
    "\n",
    "        # check each one on the duration\n",
    "        TP = 0\n",
    "        for k in range(len(matched)): \n",
    "            interval_truth = pd.Interval(truth_event[matched[k][0],2], truth_event[matched[k][0],3]) # start, end\n",
    "            interval_pred = pd.Interval(pred_event[matched[k][1],2], pred_event[matched[k][1],3])\n",
    "            if interval_truth.overlaps(interval_pred):\n",
    "                time_sorted = np.sort([truth_event[matched[k][0],2], truth_event[matched[k][0],3], \n",
    "                      pred_event[matched[k][1],2], pred_event[matched[k][1],3]]) # start, end, start, end\n",
    "                event_dur = time_sorted[2] - time_sorted[1]\n",
    "                if event_dur / (truth_event[matched[k][0],3] - truth_event[matched[k][0],2]) > dur: # at least half duration\n",
    "                     TP += 1\n",
    "\n",
    "        FN = len(truth_event[truth_event[:,-1]==label]) - TP\n",
    "        FP = len(pred_event[pred_event[:,-1]==label]) - TP\n",
    "\n",
    "        if TP != 0:\n",
    "            P_event = TP / (TP + FP) * 100; R_event = TP / (TP + FN) * 100; \n",
    "            event_result.extend([2 * P_event * R_event / (P_event + R_event)])\n",
    "        else:\n",
    "            event_result.extend([0])\n",
    "            \n",
    "    F_event.append([chick] + event_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame-based F-scores for pleasure, contact, and uncertain calls: [4.5, 77.0, 2.75]\n",
      "Event-based F-scores for pleasure, contact, and uncertain calls: [3.58, 75.04, 2.93]\n"
     ]
    }
   ],
   "source": [
    "F_frame = np.round(np.array(F_frame) * 100)\n",
    "print('Frame-based F-scores for pleasure, contact, and uncertain calls: {}'.format(\n",
    "    [elem for elem in np.mean(F_frame,0)[1:]]))\n",
    "print('Event-based F-scores for pleasure, contact, and uncertain calls: {}'.format(\n",
    "    [round(elem,2) for elem in np.mean(F_event,0)[1:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame-based average F-score: 28.08\n",
      "Event-based average F-score: 27.18\n"
     ]
    }
   ],
   "source": [
    "print('Frame-based average F-score: {}'.format(round(np.mean(np.mean(F_frame,0)[1:]), 2)))\n",
    "print('Event-based average F-score: {}'.format(round(np.mean(np.mean(F_event,0)[1:]), 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "188.014px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
