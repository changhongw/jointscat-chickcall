{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os, collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy, soundfile, librosa\n",
    "import mir_eval\n",
    "from time import time\n",
    "from fnmatch import fnmatch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from thundersvm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer  # for imputation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of audio files: 4\n",
      "85SM_2020-01-27_14-40-03.wav\n",
      "87SM_2020-01-27_15-43-59.wav\n",
      "89SF_2020-01-27_16-51-22.wav\n",
      "91SM_2020-01-30_10-20-53.wav\n",
      "Chick ID: 85 87 89 91\n"
     ]
    }
   ],
   "source": [
    "data_root = '/import/c4dm-datasets/ChickCallDataset/annotated/EUSIPCO22/'\n",
    "wav_files = []  \n",
    "with open('file_names_callType.txt', 'r') as f:\n",
    "    Lines = f.readlines()\n",
    "    for line in Lines: \n",
    "        wav_files.append(line.strip())\n",
    "        \n",
    "print('Number of audio files:', format(len(wav_files)))\n",
    "print(*wav_files, sep='\\n')\n",
    "\n",
    "# chick call annotation files\n",
    "csv_files = [file.replace('.wav', '.csv') for file in wav_files]\n",
    "chickID = [int(wav_files[k][:2]) for k in range(len(wav_files))]\n",
    "print('Chick ID:', *chickID, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chickID</th>\n",
       "      <th>callID</th>\n",
       "      <th>truth_start</th>\n",
       "      <th>truth_end</th>\n",
       "      <th>truth_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336961</td>\n",
       "      <td>0.595465</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>0.830385</td>\n",
       "      <td>1.137415</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>1.258957</td>\n",
       "      <td>1.551020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>1.659864</td>\n",
       "      <td>1.991837</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>91</td>\n",
       "      <td>3008</td>\n",
       "      <td>629.097506</td>\n",
       "      <td>629.471202</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>91</td>\n",
       "      <td>3009</td>\n",
       "      <td>632.406349</td>\n",
       "      <td>632.756825</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>91</td>\n",
       "      <td>3010</td>\n",
       "      <td>632.883809</td>\n",
       "      <td>633.269841</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>91</td>\n",
       "      <td>3011</td>\n",
       "      <td>633.361270</td>\n",
       "      <td>633.747302</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>91</td>\n",
       "      <td>3012</td>\n",
       "      <td>633.848889</td>\n",
       "      <td>634.255238</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3013 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chickID  callID  truth_start   truth_end truth_label\n",
       "0          85       0     0.000000    0.123356           1\n",
       "1          85       1     0.336961    0.595465           2\n",
       "2          85       2     0.830385    1.137415           2\n",
       "3          85       3     1.258957    1.551020           2\n",
       "4          85       4     1.659864    1.991837           2\n",
       "...       ...     ...          ...         ...         ...\n",
       "3008       91    3008   629.097506  629.471202           2\n",
       "3009       91    3009   632.406349  632.756825           2\n",
       "3010       91    3010   632.883809  633.269841           2\n",
       "3011       91    3011   633.361270  633.747302           2\n",
       "3012       91    3012   633.848889  634.255238           2\n",
       "\n",
       "[3013 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get call segs information\n",
    "anno = []\n",
    "for file in csv_files:\n",
    "    file_anno = pd.read_csv(data_root+file)\n",
    "    file_anno['chick'] = [int(file[:2])] * len(file_anno)\n",
    "    anno.append(file_anno)\n",
    "    \n",
    "anno = pd.concat(anno, axis=0, ignore_index=True)\n",
    "\n",
    "call_segs = pd.DataFrame({'chickID':[], 'callID':[], 'truth_start': [], 'truth_end': [], 'truth_label':[]})\n",
    "call_segs['chickID'] = list(anno['chick'][1::2])\n",
    "call_segs['callID'] = np.arange(len(call_segs['chickID']), dtype=int)\n",
    "call_segs['truth_start'] = list(anno['time'][0::2])\n",
    "call_segs['truth_end'] = list(anno['time'][1::2])\n",
    "call_segs['truth_label'] = list(anno['anno'][1::2])\n",
    "\n",
    "call_segs.loc[(call_segs.truth_label == 'p'),'truth_label']= 1\n",
    "call_segs.loc[(call_segs.truth_label == 'd'),'truth_label']= 2\n",
    "call_segs.loc[(call_segs.truth_label == 'q'),'truth_label']= 3\n",
    "call_segs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame size: 25ms\n",
      "MFCC feature shape: \n",
      "(24, 27189)\n",
      "(24, 27102)\n",
      "(24, 25678)\n",
      "(24, 25414)\n"
     ]
    }
   ],
   "source": [
    "sr = 44100\n",
    "hop_sample= 1103  # 25ms\n",
    "print('frame size: %sms' % (int(hop_sample/44100*1000)))\n",
    "\n",
    "# MFCC feature extraction, default: n_fft=2048, hop_length=512 \n",
    "feature = {k:[] for k in range(len(wav_files))}\n",
    "\n",
    "print('MFCC feature shape: ')\n",
    "for k in range(len(wav_files)):\n",
    "    y, sr = soundfile.read(data_root + wav_files[k])\n",
    "    y = np.mean(y,1)\n",
    "    feature[k] = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=24, hop_length=hop_sample)\n",
    "    print(feature[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_conca = np.zeros((feature[0].shape[0],1))\n",
    "chick_id = []\n",
    "\n",
    "for k in range(len(wav_files)):\n",
    "    feature_conca = np.hstack((feature_conca, feature[k]))\n",
    "    chick_id.extend([int(wav_files[k][:2])] * feature[k].shape[1])\n",
    "        \n",
    "chick_id = np.array(chick_id)\n",
    "feature_conca = np.transpose(feature_conca)\n",
    "feature_conca = feature_conca[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame-wise label_id and call_id\n",
    "frame_num = []\n",
    "label_id = np.zeros((len(chick_id)), dtype=int)   # 1=pleasure, 2=distress, 3=unknown\n",
    "call_id = np.zeros((len(chick_id)), dtype=int)\n",
    "\n",
    "for chick in range(len(wav_files)):\n",
    "    frame_num.append(feature[chick].shape[1])\n",
    "    seg_chick = call_segs[call_segs['chickID']== int(wav_files[chick][:2])]\n",
    "    sample_start = list(map(lambda x:int(x * sr / hop_sample) + sum(frame_num[:chick]), seg_chick['truth_start']))\n",
    "    sample_end = list(map(lambda x:int(x * sr / hop_sample) + sum(frame_num[:chick]), seg_chick['truth_end']))\n",
    "    \n",
    "    for k in range(len(seg_chick)): # for each sample\n",
    "        label_id[sample_start[k]:sample_end[k]] = np.zeros((sample_end[k]-sample_start[k])) + list(seg_chick['truth_label'])[k]\n",
    "        call_id[sample_start[k]:sample_end[k]] = np.zeros((sample_end[k]-sample_start[k])) + list(seg_chick['callID'])[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105383, 24) (105383,) (105383,) (105383,)\n"
     ]
    }
   ],
   "source": [
    "print(feature_conca.shape, chick_id.shape, label_id.shape, call_id.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM settings\n",
    "kernel = 'rbf'\n",
    "gpu_id = 0 # thundersvm uses GPU to train SVM classifier\n",
    "param_grid = {'C': [100,10,1], 'gamma': [.0001, .001, .01]}\n",
    "scoring = 'f1_macro'\n",
    "cv = 3\n",
    "\n",
    "F_event = []; F_frame = []\n",
    "dur = .5  # for event-based evaluation: duration of detected event should be at least 50% of the ground truth duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for resampling predictions into the same frame size as that of the joint scattering feature\n",
    "inframeSize = hop_sample / 44100 # ms\n",
    "outframeSize = 0.186 # ms\n",
    "\n",
    "subsample_rate = int(outframeSize / inframeSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subject-independent train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24802, 24) (4560, 24)\n",
      "(20405, 24) (8957, 24)\n",
      "(19087, 24) (10275, 24)\n",
      "(23792, 24) (5570, 24)\n"
     ]
    }
   ],
   "source": [
    "for chick in chickID:\n",
    "    \n",
    "    subset = np.ones((len(label_id)), dtype=int) * 100\n",
    "\n",
    "    for k in range(len(label_id)):\n",
    "        if chick_id[k] !=chick and label_id[k] != 0:  \n",
    "            subset[k] = 0\n",
    "        elif chick_id[k] == chick and label_id[k] != 0:  # assign label for annotated (onset-offset) call segments\n",
    "            subset[k] = 1\n",
    "\n",
    "    feature_tr, label_tr = feature_conca[subset == 0], label_id[subset == 0]\n",
    "    feature_te, label_te = feature_conca[subset == 1], label_id[subset == 1]\n",
    "\n",
    "    # imputation\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    feature_tr = imp.fit_transform(feature_tr)\n",
    "    feature_te = imp.transform(feature_te)\n",
    "\n",
    "    # normalisation\n",
    "    stdscaler = StandardScaler()\n",
    "    feature_tr = stdscaler.fit_transform(feature_tr)\n",
    "    feature_te = stdscaler.transform(feature_te)\n",
    "    print(feature_tr.shape, feature_te.shape)\n",
    "\n",
    "    # classification\n",
    "    clf =  GridSearchCV(SVC(kernel=kernel, gpu_id=gpu_id), param_grid=param_grid, cv=cv, scoring=scoring)\n",
    "    clf = clf.fit(feature_tr, label_tr)\n",
    "    label_pred = clf.predict(feature_te)    \n",
    "    \n",
    "    ########## event-based evaluation ##########\n",
    "    # majority vote of frame labels for each segment\n",
    "    call_id_test = call_id[subset == 1]\n",
    "    _, idx = np.unique(call_id_test, return_index=True)\n",
    "    call_id_test_unique = call_id_test[np.sort(idx)]\n",
    "\n",
    "    seg_label_te = []; seg_label_pred = []\n",
    "    for call in call_id_test_unique:\n",
    "        seg_label_te.append(collections.Counter(label_te[call_id_test==call]).most_common(1)[0][0])\n",
    "        seg_label_pred.append(collections.Counter(label_pred[call_id_test==call]).most_common(1)[0][0])\n",
    "\n",
    "    report = pd.DataFrame(classification_report(seg_label_te, seg_label_pred, output_dict=True))\n",
    "    F_event.append([chick, report['1']['f1-score'], report['2']['f1-score'], report['3']['f1-score']])\n",
    "    \n",
    "    ########## frame-based evaluation ##########\n",
    "    # test label back into frame level\n",
    "    label_te_ori = label_id[chick_id==chick] # include label=0\n",
    "    label_pred_true = np.zeros((len(label_te_ori)), dtype=int)\n",
    "    label_pred_true[label_te_ori!=0] = label_pred\n",
    "\n",
    "    label_te = label_te_ori\n",
    "    label_pred = label_pred_true\n",
    "\n",
    "    # resample into the same frame size as that of the JTFS feature\n",
    "    label_te = label_te[::subsample_rate]\n",
    "    label_pred = label_pred[::subsample_rate]\n",
    "    \n",
    "    report = pd.DataFrame(classification_report(label_te, label_pred, output_dict=True))\n",
    "    F_frame.append([chick, report['1']['f1-score'], report['2']['f1-score'], report['3']['f1-score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame-based F-scores for pleasure, contact, and uncertain calls: [16.77, 91.0, 8.46]\n",
      "Event-based F-scores for pleasure, contact, and uncertain calls: [18.88, 87.31, 5.67]\n"
     ]
    }
   ],
   "source": [
    "print('Frame-based F-scores for pleasure, contact, and uncertain calls: {}'.format(\n",
    "    [round(elem, 2) for elem in np.mean(F_frame,0)[1:]*100]))\n",
    "print('Event-based F-scores for pleasure, contact, and uncertain calls: {}'.format(\n",
    "    [round(elem, 2) for elem in np.mean(F_event,0)[1:]*100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame-based average F-score: 38.74\n",
      "Event-based average F-score: 37.29\n"
     ]
    }
   ],
   "source": [
    "print('Frame-based average F-score: {}'.format(round(np.mean(np.mean(F_frame,0)[1:]*100), 2)))\n",
    "print('Event-based average F-score: {}'.format(round(np.mean(np.mean(F_event,0)[1:]*100), 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "188.014px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
